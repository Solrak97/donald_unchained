{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Env Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "TWEETS_PATH = \"../../Donald-Tweets!.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv(TWEETS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing non text tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trailing chars remotion\n",
    "def remove_trailings(tweet):\n",
    "    return re.sub(r'\\S*_\\s*$', '', tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separation of \\n\n",
    "def add_trailing_space(tweet):\n",
    "    return re.sub(r'\\n', ' \\n ', tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL Remotion\n",
    "\n",
    "def remove_urls(tweet):\n",
    "    return re.sub(r'http\\S+', '', tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_retweets(tweet):\n",
    "    return re.sub(r'RT @\\S*:', '', tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = tweets_df[tweets_df[\"Type\"] == \"text\"]\n",
    "tweets_df[\"Tweet_Text\"] = tweets_df[\"Tweet_Text\"].apply(lambda x: x.strip())\n",
    "tweets_df[\"Tweet_Text\"] = tweets_df[\"Tweet_Text\"].apply(add_trailing_space)\n",
    "tweets_df[\"Tweet_Text\"] = tweets_df[\"Tweet_Text\"].apply(remove_urls)\n",
    "tweets_df[\"Tweet_Text\"] = tweets_df[\"Tweet_Text\"].apply(remove_retweets)\n",
    "tweets_df[\"Tweet_Text\"] = tweets_df[\"Tweet_Text\"].apply(remove_trailings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the transition Index and Sparse Transition Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_matrix = {}\n",
    "token_counter = 0\n",
    "unique_token_counter = 0\n",
    "tweet_starters = []\n",
    "\n",
    "for tweet in tweets_df[\"Tweet_Text\"]:\n",
    "    \n",
    "    split_tweet = tweet.split()\n",
    "    for idx, token in enumerate(split_tweet):\n",
    "        \n",
    "        token_counter += 1 \n",
    "\n",
    "        # First time looking for a key top level token\n",
    "        if token not in transition_matrix:\n",
    "\n",
    "            transition_matrix[token] = {}\n",
    "            unique_token_counter += 1\n",
    "\n",
    "            if idx == 0:\n",
    "                if \"@\" not in token:\n",
    "                    tweet_starters.append(token)\n",
    "\n",
    "\n",
    "        # Next word lookup\n",
    "        if idx + 1 < len(split_tweet):\n",
    "            next_token = split_tweet[idx + 1]\n",
    "            \n",
    "            if next_token not in transition_matrix[token]:\n",
    "                transition_matrix[token][next_token] = 0\n",
    "            \n",
    "            transition_matrix[token][next_token] += 1\n",
    "\n",
    "        # Add end of tweet token state\n",
    "        else:\n",
    "            if \"<EOT>\" not in transition_matrix[token]:\n",
    "                transition_matrix[token][\"<EOT>\"] = 0\n",
    "            transition_matrix[token][\"<EOT>\"] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transitions for Today: {'we': 3, 'in': 1, 'I': 2, 'they': 1, 'will': 3, 'is': 3, 'proves': 1, 'did': 1, 'we,': 1, 'National': 1, 'polls,': 1, '\"We': 1}\n",
      "Unique Tokens: 19280\n",
      "Dataset Tokens: 109465\n",
      "Tweet Starters: 1893\n"
     ]
    }
   ],
   "source": [
    "print(f\"Transitions for Today: {transition_matrix['Today']}\")\n",
    "print(f\"Unique Tokens: {unique_token_counter}\")\n",
    "print(f\"Dataset Tokens: {token_counter}\")\n",
    "print(f\"Tweet Starters: {len(tweet_starters)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test run before moving it into a proper python model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"@PATRIOT4657:\n",
      " \"@PATRIOT4657: @megynkelly @realDonaldTrump Will be great interview tonight.\n"
     ]
    }
   ],
   "source": [
    "word_treshold = 20\n",
    "\n",
    "first_word = random.choice(tweet_starters)\n",
    "current_word = first_word\n",
    "\n",
    "sentence = \"\"\n",
    "\n",
    "print(first_word)\n",
    "\n",
    "while current_word != \"<EOT>\":\n",
    "\n",
    "    sentence += f\" {current_word}\"\n",
    "\n",
    "    current_word_dict = transition_matrix[current_word]\n",
    "\n",
    "    keys = [key for key in current_word_dict]\n",
    "    values = [current_word_dict[key] for key in current_word_dict]\n",
    "\n",
    "    current_word = random.choices(keys, weights=values)[0]\n",
    "\n",
    "    if current_word == \"<EOT>\":\n",
    "        break\n",
    "\n",
    "\n",
    "print(sentence)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
